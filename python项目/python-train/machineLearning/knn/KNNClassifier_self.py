import numpy as np
from math import sqrt
from collections import Counter

class kNNClassifier_self:
    def __init__(self, k):
        """初始化分类器"""
        assert k >= 1, "k must be valid"
        self.k = k
        self._X_train = None
        self._y_train = None
    '''函数初始化，做合理性判断'''
    def fit(self, X_train, y_train):
        """根据训练数据集X_train和y_train训练kNN分类器"""
        # shape[0] 只输出行数 shape[1] 只输出列数，shape函数输出行数和列数
        assert X_train.shape[0] == y_train.shape[0], \
            "the size of X_train must be equal to the size of y_train"
        assert self.k <= X_train.shape[0], \
            "the size of X_train must be at least k"
        self._X_train = X_train
        self._y_train = y_train
        return self

    '''进行数据预测'''
    def predict(self, X_predict):
        """给定待预测数据集X_predict，返回表示X_predict结果的向量"""
        assert self._X_train is not None and self._y_train is not None, \
            "must fit before predict!"
        # 列数不想等
        assert X_predict.shape[1] == self._X_train.shape[1], \
            "the feature number of X_predict must be equal to X_train"
        y_predict = [self._predict(x) for x in X_predict]
        return np.array(y_predict)

    '''约定为不在类的外面直接调用这个方法，但是也可以调用'''
    def _predict(self, x):
        # 计算每一个点到给定点的距离
        distances = [sqrt(np.sum((x_train - x) ** 2)) for x_train in self._X_train]
        # 按照最近点进行排序，输出索引
        nearest = np.argsort(distances)
        # 获取索引对应的 y_train中的值
        topK_y = [self._y_train[i] for i in nearest]
        # 统计
        votes = Counter(topK_y)
        # print('distance',distances)
        # print('nearest',nearest)
        # print('topK_y',topK_y)
        # print('votes',votes)
        # print(votes.most_common(1))
        # print(votes.most_common(1)[0])
        print('votes(1)[0][0]',votes.most_common(1)[0][0])
        '''distance [3.327160951922825, 3.0066592756745814, 0.7348469228349537, 2.1330729007701543, 3.1543620591175006, 0.374165738677394, 2.647640458974745, 0.5744562646538031, 0.9643650760992953, 1.489966442575134, 0.5477225575051662, 3.408812109811863, 1.3076696830622019, 0.26457513110645864, 1.5684387141358118, 0.8999999999999999, 3.2046840717924128, 0.7348469228349536, 2.3685438564654024, 1.2727922061357855, 1.5132745950421556, 0.24494897427831822, 1.489966442575134, 3.0446674695276656, 3.5454195802471675, 1.7578395831246947, 1.8841443681416774, 3.0232432915661946, 1.7000000000000002, 2.8266588050205135, 1.2369316876852978, 0.22360679774997935, 2.9883105594967865, 2.9698484809834995, 1.6941074346097416, 2.9698484809834995, 3.283291031876401, 1.8165902124584954, 2.9376861643136762, 2.8861739379323623, 1.0908712114635717, 2.9359836511806394, 3.3541019662496847, 3.10322412983658, 3.184336665618131, 2.109502310972899, 2.7239676943752467, 2.8319604517012587, 1.0630145812734653, 2.0566963801203135, 1.2206555615733705, 3.246536616149585, 2.949576240750525, 1.486606874731851, 3.24499614791759, 3.029851481508623, 3.5270384177096794, 1.8788294228055935, 0.9949874371066201, 2.9563490998188966, 0.17320508075688815, 2.951270912674741, 0.36055512754639923, 1.1789826122551597, 0.6999999999999996, 0.5477225575051663, 2.4248711305964283, 3.1416556144810017, 3.0397368307141326, 0.9746794344808961, 0.8366600265340758, 1.0677078252031318, 2.7676705006196096, 1.8027756377319948, 1.1747340124470729, 3.0199337741082997, 2.785677655436823, 3.1827660925679098, 1.0440306508910553, 1.5427248620541516, 1.1832159566199232, 2.2715633383201097, 1.9646882704388506, 1.4177446878757827, 0.8366600265340756, 2.6870057685088806, 3.095157508108432, 0.40000000000000036, 0.26457513110645864, 1.0246950765959597, 2.9899832775452104, 0.9695359714832661, 2.8053520278211073, 3.3015148038438356, 2.3790754506740637, 3.057776970284131, 3.1937438845342623, 1.0908712114635715, 3.1400636936215163, 1.1532562594670797, 2.0928449536456353, 0.556776436283002, 2.2956480566497994, 0.14142135623730995, 0.5744562646538027, 3.1336879231984796, 0.6708203932499366, 0.9327379053088817, 1.0344080432788596, 2.2912878474779204, 0.4242640687119284, 2.0445048300260873, 0.5477225575051662, 3.5888716889852725, 0.5000000000000004, 0.728010988928052, 2.7784887978899606, 1.2569805089976533, 2.8124722220850464, 2.6476404589747453]
            nearest [103  60  31  21  88  13  62   5  87 110 114  10 112  65 101 104   7 106
              64 115  17   2  84  70  15 107   8  91  69  58  89 108  78  48  71  97
              40  99  74  63  80  50  30 117  19  12  83  53   9  22  20  79  14  34
              28  25  73  37  57  26  82 111  49 100  45   3  81 109 102  18  94  66
               6 119  85  46  72 116  76  92 118  29  47  39  41  38  52  61  59  33
              35  32  90   1  75  27  55  68  23  95  86  43 105  98  67   4  77  44
              96  16  54  51  36  93   0  42  11  56  24 113]
            topK_y [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 2]
            votes Counter({2: 41, 0: 40, 1: 39})'''
        # 获取前1个元素
        return votes.most_common(1)[0][0]

    def __repr__(self):
        return "kNN(k=%d)" % self.k

from machineLearning.knn.accurcay.metrics import accuracy_score

def score(self, X_test, y_test):
    """根据X_test进行预测, 给出预测的真值y_test，计算预测算法的准确度"""
    y_predict = self.predict(X_test)
    return accuracy_score(y_test, y_predict)
